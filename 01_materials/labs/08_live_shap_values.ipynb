# Import necessary libraries
import shap
import numpy as np
import xgboost
import tensorflow as tf
from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_diabetes
import matplotlib.pyplot as plt

# ========== 1️⃣ TREE-BASED MODEL (XGBoost) ==========
# Load Boston housing dataset
X, y = shap.datasets.boston()

# Train an XGBoost model
xgb_model = xgboost.XGBRegressor().fit(X, y)

# Explain the model using SHAP
xgb_explainer = shap.Explainer(xgb_model, X)
xgb_shap_values = xgb_explainer(X)

# Plot SHAP summary (global feature importance)
shap.summary_plot(xgb_shap_values, X)

# ========== 2️⃣ DEEP LEARNING MODEL (TensorFlow/Keras) ==========
# Generate synthetic data
X_dl = np.random.randn(100, 10)  # 100 samples, 10 features
y_dl = np.random.randn(100, 1)

# Build a simple neural network model
dl_model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(16, activation="relu", input_shape=(10,)),
    tf.keras.layers.Dense(1)
])
dl_model.compile(optimizer="adam", loss="mse")

# Train the model
dl_model.fit(X_dl, y_dl, epochs=5, verbose=0)

# Explain deep learning model using SHAP
dl_explainer = shap.Explainer(dl_model, X_dl)
dl_shap_values = dl_explainer(X_dl)

# Plot SHAP summary for deep learning model
shap.summary_plot(dl_shap_values, X_dl)

# ========== 3️⃣ LINEAR MODEL (Logistic Regression) ==========
# Load diabetes dataset
X_lin, y_lin = load_diabetes(return_X_y=True)

# Train a linear regression model
lin_model = LinearRegression().fit(X_lin, y_lin)

# Explain the model using SHAP
lin_explainer = shap.Explainer(lin_model, X_lin)
lin_shap_values = lin_explainer(X_lin)

# Plot SHAP summary for linear model
shap.summary_plot(lin_shap_values, X_lin)

# ========== 4️⃣ INTERPRETABILITY VISUALIZATIONS ==========
# Force plot (explaining a single prediction)
shap.force_plot(xgb_explainer.expected_value, xgb_shap_values[0], X.iloc[0])

# Dependence plot (feature interaction)
shap.dependence_plot("CRIM", xgb_shap_values, X)  # Example feature: "CRIM"

# Decision plot (step-by-step feature impact)
shap.decision_plot(xgb_explainer.expected_value, xgb_shap_values, X)

# Show all plots
plt.show()
